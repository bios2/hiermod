---
title: "Gaussian process"
title-slide-attributes: 
  data-background-image: ../img/bg.jpg
  data-background-size: full
author: "Guillaume Blanchet -- Andrew MacDonald"
date: "2025-05-08"
execute:
  echo: true
format: 
  revealjs:
    theme: [default]
    logo: ../img/UdeS_logo_h_rgbHR.png
    transition: slide
    background-transition: fade
---

## Hierarchical models so far {style="font-size: 0.9em;"}

. . .

**An already (very !) general formulation**

::: {style="font-size: 0.75em"}
So far, we have built hierarchical models that can be integrated into the following framework.
:::

. . .

::: {style="font-size: 0.8em"}
$$(\mathbf{y}|\mathbf{X},\mathbf{Z}, \boldsymbol{\beta}, \mathbf{b}, \sigma_\mathbf{y}^2)\sim \mathcal{MVN}(\mathbf{X} \boldsymbol{\beta} + \mathbf{Z}\mathbf{b}, \sigma_\mathbf{y}^2\mathbf{I})$$
:::

. . .

::: {style="font-size: 0.68em"}

where

$$\mathbf{b}\sim \mathcal{MVN}(\mu, \mathbf{\Sigma})$$
:::

. . .

::: {style="font-size: 0.65em"}

- $\mathbf{y}$ is a vector quantifying a response variable of length $n$
- $\mathbf{X}$ is a matrix of explanatory variables with $n$ rows (samples) and $p$ columns (explanatory variables) 
- $\boldsymbol{\beta}$ is a vector $p$ pararameters weighting the importance of each explanatory variables in $\mathbf{X}$
- $\sigma_\mathbf{y}^2$ is a measure of variance of the error in the regression model
- $\mathbf{I}$ is an $n \times n$ identity matrix 

:::: {style="color: blue"}
- $\mathbf{Z}$ is designed matrix of "explanatory" variables with $n$ rows (samples) and $q$ columns 
- $\mu$ is a vector defining the average importance of hierarchical parameters
- $\mathbf{\Sigma}$ is a matrix defining the covariance structure of hierarchical parameters
::::
:::

## Hierarchical models so far {style="font-size: 0.9em;"}

**An already (very !) general formulation**

Another way to write this generalized formulation is

$$\mathbf{y}_i = \mathbf{X}_{ij} \boldsymbol{\beta}_j + \mathbf{Z}_{ik}\mathbf{b}_{k} + \boldsymbol{\varepsilon}_{ij}$$
where

$$\mathbf{b}\sim \mathcal{MVN}(\mu, \mathbf{\Sigma})$$
and 

$$\varepsilon \sim \mathcal{N}(0, \sigma^2)$$

## An even more complex hierarchical models! {style="font-size: 0.85em;"}

So far we have seen many (!) types of hierarchical models, which got increasingly more complex in their structure.

. . .

Let's continue on that slippery slope... 

. . . 

Would you know how to constraint (spatially, temporally, phylogenetically, etc.) such a model ?

![](https://www.i2symbol.com/pictures/emojis/f/c/3/2/fc326fef420c2381348864310ea8efa1_384.png){fig-align="center" width=30%}

## An even more complex hierarchical models! {style="font-size: 0.85em;"}

If we get back to a model that has a single hierarchy on the intercept such that
$$\mathbf{y} \sim \mathcal{N}(\mathbf{b},\sigma^2)$$

. . .

where
$$\mathbf{b} \sim \mathcal{N}(\mu, \sigma^2).$$

. . . 

If we want to account for a constraint on the previously presented model, we can rewrite the equation fo $\mathbf{b}$ as 
$$\mathbf{b} \sim \mathcal{N}\left(\mu, f(d)\right)$$

. . .

where

$f(d)$ is a function of a (spatial, temporal, phylogenetic, ...) distance matrix

## An even more complex hierarchical models! {style="font-size: 0.85em;"}

$$\mathbf{b} \sim \mathcal{N}\left(\mu, f(d)\right)$$

. . .

What this equation means conceptually is that the variance associated to $\mathbf{b}$ is not a constant, it changes based on distance (across space, time, phylogeny, etc.). This is known as a **Gaussian process**.

![](https://t4.ftcdn.net/jpg/05/69/50/21/240_F_569502134_d2TO2BeHCbvOn4imEyFJJ5n6HdiyJg9X.jpg){fig-align="center" width=30%}

## A bit of history

. . .

In statistics, Gaussian processes have a unique history. The development of this type of model is closely linked to the estimation of mineral deposits. 

. . .

Spatial Gaussian processes are also called **geostatistical** models, where the prefix *geo* refers to geology, not geography, as one may be led to believe.

. . .

As mining engineers are at the root of the development of Gaussian processes, the language associated with this type of model is influenced by this field. 

## A bit of history

Gaussian processes have been developed in the 1950s by 

::::{.columns}
::: {.column width="50%"}
![](https://www.nae.edu/File.aspx?id=191706){fig-align="center" width=60%}

:::::{style="font-size: 0.9em;"}
Daniel G. Krige (1919–2013)
:::::
:::
::: {.column width="50%"}
![](https://upload.wikimedia.org/wikipedia/commons/5/5c/Georges_Matheron.jpg){fig-align="center" width=75%}

:::::{style="font-size: 0.9em;"}
Georges Mathéron (1930–2000)
:::::

:::
::::

## Assumption with Gaussian processes

. . .

In general, when defining a Gaussian process, we make the following assumptions:

. . .

- The closer two samples are, the more similar they are.

. . .

- After a certain distance, it is no longer necessary to consider that a sample influences another.

. . .


**Note** The distance of influence of a sample on another can be different depending on what is being studied, where it is being studied and when it is being studied

## $f(d)$

. . .

So, what does $f(d)$ looks like exactly ?

. . .

In theory, $f(d)$ can be anything... 

. . .

However, in practice, there are particularities of the functions that are defined by the assumptions we impose on our model.

. . . 

Here is a classic structure these variance function take

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")
```

## $f(d)$ - A bit of vocabulary

. . .

**Nugget effect**

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 1,
       y0 = 0,
       x1 = 1,
       y1 = 2,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```

## $f(d)$ - A bit of vocabulary

**Range**


```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 0,
       y0 = 1,
       x1 = 30,
       y1 = 1,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```


## $f(d)$ - A bit of vocabulary

**Sill**

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 60,
       y0 = 2,
       x1 = 60,
       y1 = 7,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```

## $f(d)$ - types of functions {style="font-size: 0.85em;"}

. . .

Many functions that have been proposed have this general shape

. . . 

Let's first study the exponential function

$$C_0 + C_1 \left(1-e^{-d/a}\right)$$

. . .

where

- $C_0$ is the nugget effect

. . .

- $C_1$ is the sill

. . .

- $d$ is the distance

. . .

- $a$ is the range

## Exponential function

Nugget : 2 -- Sill : 5 -- Range : 10

```{r, echo = FALSE}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")
```

## An illustrative example {style="font-size: 0.9em;"}

. . . 

To present how Gaussian processes can be used, let's study the distribution of *Sylvilagus oviparus* in Montréal.

. . .

**A few characteristics of** ***Sylvilagus oviparus***

- They are found mainly in urban parks of Montréal and are very efficient at hiding in hollow trees and burrows.

. . .

- They lay their eggs (often pastel-coloured) on the Sunday following the first full moon after the spring equinox. 

. . .

- They move well in an urban  setting and are not affected by the level of urbanisation


## A typical member of the species

![](https://t3.ftcdn.net/jpg/05/78/06/66/240_F_578066681_18vcVGHuSLDc4dQE6HTXG8qsn2tjSHMy.jpg){fig-align="center" width=75%}

## Distribution of *S. oviparus* in Montréal {style="font-size: 0.9em;"}

. . .

In 2015, a survey was carried out to find *Sylvilagus oviparus* in Montréal's park. Here are the data
. . .

::::{.columns}
:::{.column width="60%"}
```{r, echo = FALSE}
library(mapview)
explan<-readRDS("./slides/data/explanaNest.RDS")
lapin <- readRDS("./slides/data/lapin.RDS")

# Carte de présence absence en 2015
present <- explan[lapin$PA == 1,]
absent <- explan[lapin$PA == 0,]

# Map species
mapview(list(present, absent),
        col.regions = list("lightblue", "hotpink"),
        color = list("blue", "hotpink"),
        legend = list(TRUE, TRUE))
```
:::
:::{.column width="40%"}

:::::{style="font-size: 0.8em;"}
Within the censused park

- <span style="color:blue;">Blue parks</span> : observed

- <span style="color:#FF33FF;">Pink parks</span> : not observed
:::::
:::
::::

## Model

. . .

Since we have presence-absence data

$$P(y = 1) = \frac{\exp(b)}{1 - \exp(b)}$$

. . .

where 
$$b \sim{\cal N}\left(0, C_0 +C_1\left(1 - e^{\frac{-d}{a}}\right)\right)$$

## Fitting the model

If we estimate the parameters of the model presented in the previous slide we get a Gaussian process that looks like


```{r, echo = FALSE, fig.align="center"}
expVario <- function(d, nugget = 0.2, sill = 4, range = 150){
  nugget + sill * (1 - exp(-d / range))
}

# The parameters were slightly 

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 700, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 4.1),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")


```

. . .

What can we learn from this model ?

## Kringing

If we want to interpolate across the region of interest, this is known as **kriging**.

. . .

**Simple kriging**

So far, we have seen the most simplistic Gaussian process where there is not even any intercept that is estimated. In short, the model is constructed using only the covariance function. 

. . .

In a linear regression perspective, this means that

$$\mathbf{y}\sim\mathcal{N}(0, f(d))$$

## Kringing {style="font-size: 0.9em;"}

::: {style="font-size: 1.1em;"}
**Ordinary kriging** 
:::

If we want to account for an intercept in the model such that 

$$\mathbf{y}\sim\mathcal{N}(\beta_0, f(d))$$

This is known as **ordinary kriging**.

. . .

::: {style="font-size: 1.1em;"}
**Universal kriging** 
:::

If we want to account for one or more explanatory variables in the model such that 

$$\mathbf{y}\sim\mathcal{N}(\beta_0 + \mathbf{X}\beta, f(d))$$
This is known as **Universal kriging**.

## Prediction map

```{r, echo =FALSE}
lapinMtlraster <- readRDS("./slides/data/lapinMtl.RDS")
mapview::mapview(lapinMtlraster)
```
