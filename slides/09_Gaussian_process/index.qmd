---
title: "Gaussian process"
title-slide-attributes: 
  data-background-image: ../img/bg.jpg
  data-background-size: full
author: "Guillaume Blanchet -- Andrew MacDonald"
date: "2025-05-09"
execute:
  echo: true
format: 
  revealjs:
    theme: [default]
    logo: ../img/UdeS_logo_h_rgbHR.png
    transition: slide
    background-transition: fade
---

## Hierarchical models so far {style="font-size: 0.9em;"}

. . .

**An already (very !) general formulation**

::: {style="font-size: 0.75em"}
So far, we have built hierarchical models that can be integrated into the following framework.
:::

. . .

::: {style="font-size: 0.8em"}
$$(\mathbf{y}|\mathbf{X},\mathbf{Z}, \boldsymbol{\beta}, \mathbf{b}, \sigma_\mathbf{y}^2)\sim \mathcal{MVN}(\mathbf{X} \boldsymbol{\beta} + \mathbf{Z}\mathbf{b}, \sigma_\mathbf{y}^2\mathbf{I})$$
:::

. . .

::: {style="font-size: 0.68em"}

where

$$\mathbf{b}\sim \mathcal{MVN}(\mu, \mathbf{\Sigma})$$
:::

. . .

::: {style="font-size: 0.65em"}

- $\mathbf{y}$ is a vector quantifying a response variable of length $n$
- $\mathbf{X}$ is a matrix of explanatory variables with $n$ rows (samples) and $p$ columns (explanatory variables) 
- $\boldsymbol{\beta}$ is a vector $p$ pararameters weighting the importance of each explanatory variables in $\mathbf{X}$
- $\sigma_\mathbf{y}^2$ is a measure of variance of the error in the regression model
- $\mathbf{I}$ is an $n \times n$ identity matrix 

:::: {style="color: blue"}
- $\mathbf{Z}$ is designed matrix of "explanatory" variables with $n$ rows (samples) and $q$ columns 
- $\mu$ is a vector defining the average importance of hierarchical parameters
- $\mathbf{\Sigma}$ is a matrix defining the covariance structure of hierarchical parameters
::::
:::

## Hierarchical models so far {style="font-size: 0.9em;"}

**An already (very !) general formulation**

Another way to write this generalized formulation is

$$\mathbf{y}_i = \mathbf{X}_{ij} \boldsymbol{\beta}_j + \mathbf{Z}_{ik}\mathbf{b}_{k} + \boldsymbol{\varepsilon}_{ij}$$
where

$$\mathbf{b}\sim \mathcal{MVN}(\mu, \mathbf{\Sigma})$$
and 

$$\varepsilon \sim \mathcal{N}(0, \sigma^2)$$

## An even more complex hierarchical models! {style="font-size: 0.85em;"}

So far we have seen many (!) types of hierarchical models, which got increasingly more complex in their structure.

. . .

Let's continue on that slippery slope... 

. . . 

Would you know how to constraint (spatially, temporally, phylogenetically, etc.) such a model ?

![](https://www.i2symbol.com/pictures/emojis/f/c/3/2/fc326fef420c2381348864310ea8efa1_384.png){fig-align="center" width=30%}

## An even more complex hierarchical models! {style="font-size: 0.85em;"}

If we get back to a model that has a single hierarchy on the intercept such that
$$\mathbf{y} \sim \mathcal{N}(\mathbf{b},\sigma^2)$$

. . .

where
$$\mathbf{b} \sim \mathcal{N}(\mu, \sigma^2).$$

. . . 

If we want to account for a constraint on the previously presented model, we can rewrite the equation fo $\mathbf{b}$ as 
$$\mathbf{b} \sim \mathcal{N}\left(\mu, f(d)\right)$$

. . .

where $f(d)$ is a function of a (spatial, temporal, phylogenetic, ...) distance matrix

## An even more complex hierarchical models! {style="font-size: 0.85em;"}

$$\mathbf{b} \sim \mathcal{N}\left(\mu, f(d)\right)$$

. . .

What this equation means conceptually is that the variance associated to $\mathbf{b}$ is not a constant, it changes based on distance (across space, time, phylogeny, etc.). This is known as a **Gaussian process**.

![](https://t4.ftcdn.net/jpg/05/69/50/21/240_F_569502134_d2TO2BeHCbvOn4imEyFJJ5n6HdiyJg9X.jpg){fig-align="center" width=30%}

## A bit of history

. . .

In statistics, Gaussian processes have a unique history. The development of this type of model is closely linked to the estimation of mineral deposits. 

. . .

Spatial Gaussian processes are also called **geostatistical** models, where the prefix *geo* refers to geology, not geography, as one may be led to believe.

. . .

As mining engineers are at the root of the development of Gaussian processes, the language associated with this type of model is influenced by this field. 

## A bit of history

Gaussian processes have been developed in the 1950s by 

::::{.columns}
::: {.column width="50%"}
![](https://www.nae.edu/File.aspx?id=191706){fig-align="center" width=60%}

:::::{style="font-size: 0.9em;"}
Daniel G. Krige (1919–2013)
:::::
:::
::: {.column width="50%"}
![](https://upload.wikimedia.org/wikipedia/commons/5/5c/Georges_Matheron.jpg){fig-align="center" width=75%}

:::::{style="font-size: 0.9em;"}
Georges Mathéron (1930–2000)
:::::

:::
::::

## Assumption with Gaussian processes

. . .

In general, when defining a Gaussian process, we make the following assumptions:

. . .

- The closer two samples are, the more similar they are.

. . .

- After a certain distance, it is no longer necessary to consider that a sample influences another.

. . .


**Note** The distance of influence of a sample on another can be different depending on what is being studied, where it is being studied and when it is being studied

## $f(d)$

. . .

So, what does $f(d)$ looks like exactly ?

. . .

In theory, $f(d)$ can be anything... 

. . .

However, in practice, there are particularities of the functions that are defined by the assumptions we impose on our model.

. . . 

Here is a classic structure these variance function take

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")
```

## $f(d)$ - A bit of vocabulary

. . .

**Nugget effect**

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 1,
       y0 = 0,
       x1 = 1,
       y1 = 2,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```

## $f(d)$ - A bit of vocabulary

**Range**


```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 0,
       y0 = 1,
       x1 = 30,
       y1 = 1,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```


## $f(d)$ - A bit of vocabulary

**Sill**

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 60,
       y0 = 2,
       x1 = 60,
       y1 = 7,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```

## $f(d)$ - types of functions {style="font-size: 0.85em;"}

. . .

Many functions that have been proposed have this general shape

. . . 

Let's first study the exponential function

$$C_0 + C_1 \left(1-e^{-d/a}\right)$$

. . .

where

- $C_0$ is the nugget effect

. . .

- $C_1$ is the sill

. . .

- $d$ is the distance

. . .

- $a$ is the range

## Exponential function

Nugget : 2 -- Sill : 5 -- Range : 10

```{r, echo = FALSE}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")
```

## Matérn function

:::{style="font-size: 0.65em;"}
$$C_1\frac{2^{1-\nu}}{\Gamma(\nu)}\left(\sqrt{2\nu}\frac{d}{a}\right)^\nu K_\nu\left(\sqrt{2\nu}\frac{d}{a}\right)$$
:::

. . . 


:::{style="font-size: 0.65em;"}
where

- $\Gamma(\nu) = (\nu - 1)!$

- $K_\nu$ is a modified Bessel function

- $d$ is the distance

- $a$ is the range

- $\nu$ is a strictly positive parameter giving flexibility to the left tail of the function
  - if $\nu = 0.5$ the function converges to an exponential function $\left(C_1\left(1 - e^{\frac{-d}{a}}\right)\right)$
  - if $\nu \rightarrow \infty$ the function converges to an Gaussian function (also known as the exponentiated quadratic function) $\left(C_1\left(1 - e^{\frac{-d^2}{2a^2}}\right)\right)$
:::

## Matérn function

Sill : 5 -- Range : 10 -- $\nu$ : 0.5

```{r, echo = FALSE}
library(gstat)
matVario.5 <- show.vgms(sill = 5,
                        model = "Mat", 
                        range = 10,
                        kappa = 0.5,
                        max = 100)

plot(matVario.5$panel.args[[1]]$x, matVario.5$panel.args[[1]]$y,
     type = "l",
     lwd = 5,
     bty = "L",
     ylim = c(0, 7),
     las = 1,
     xlab = "Distance",
     ylab = "Variance",
     cex.lab = 2.5,
     cex.axis = 2,
     col = "blue")
```

## Matérn function

Sill : 5 -- Range : 10 -- $\nu$ : 5

```{r, echo = FALSE}
library(gstat)
matVario5 <- show.vgms(sill = 5,
                       model = "Mat", 
                       range = 10,
                       kappa = 5,
                       max = 100)

plot(matVario5$panel.args[[1]]$x, matVario5$panel.args[[1]]$y,
     type = "l",
     lwd = 5,
     bty = "L",
     ylim = c(0, 7),
     las = 1,
     xlab = "Distance",
     ylab = "Variance",
     cex.lab = 2.5,
     cex.axis = 2,
     col = "blue")
```

## An illustrative example {style="font-size: 0.9em;"}

. . . 

To present how Gaussian processes can be used, let's study the distribution of *Sylvilagus oviparus* in Montréal.

. . .

**A few characteristics of** ***Sylvilagus oviparus***

- They are found mainly in urban parks of Montréal and are very efficient at hiding in hollow trees and burrows.

. . .

- They move well in an urban  setting and are not affected by the level of urbanisation

. . .

- They lay their eggs (often pastel-coloured) on the Sunday following the first full moon after the spring equinox. 


## A typical member of the species

![](https://t3.ftcdn.net/jpg/05/78/06/66/240_F_578066681_18vcVGHuSLDc4dQE6HTXG8qsn2tjSHMy.jpg){fig-align="center" width=75%}

## Distribution of *S. oviparus* in Montréal {style="font-size: 0.9em;"}

. . .

In 2015, a survey was carried out to find *Sylvilagus oviparus* in Montréal's park. Here are the data
. . .

::::{.columns}
:::{.column width="60%"}
```{r, echo = FALSE}
library(mapview)
explan<-readRDS("./slides/data/explanaNest.RDS")
lapin <- readRDS("./slides/data/lapin.RDS")

# Carte de présence absence en 2015
present <- explan[lapin$PA == 1,]
absent <- explan[lapin$PA == 0,]

# Map species
mapview(list(present, absent),
        col.regions = list("lightblue", "hotpink"),
        color = list("blue", "hotpink"),
        legend = list(TRUE, TRUE))
```
:::
:::{.column width="40%"}

:::::{style="font-size: 0.8em;"}
Within the censused park

- <span style="color:blue;">Blue parks</span> : observed

- <span style="color:#FF33FF;">Pink parks</span> : not observed
:::::
:::
::::

## Model

. . .

Since we have presence-absence data

$$P(y = 1) = \frac{\exp(b)}{1 - \exp(b)}$$

. . .

where 
$$b \sim{\cal N}\left(0, C_0 +C_1\left(1 - e^{\frac{-d}{a}}\right)\right)$$

## Fitting the model

```{r, echo = FALSE, eval = FALSE}
library(sf)
library(terra)
library(vegan)
library(INLA)

lapin <- readRDS("./slides/data/lapin.RDS")
explan <- readRDS("./slides/data/explanaNest.RDS")
mtl <- readRDS("./slides/data/mtl.RDS")

#===============================
# Building presence-absence data
#===============================
# Extract coordinates
lapinCoord <- st_coordinates(st_centroid(explan))

# Build PCNM for coordinates
PCNM <- pcnm(dist(lapinCoord))

# Presence-absence
lapin$PA <- ifelse(sign(PCNM$vectors[,6])<0, 0, 1)

#==================================================
# Building model - I cheated to make it fast and
# the Matern function was used, not the exponential
#==================================================
# INLA Mesh
mesh <- inla.mesh.2d(boundary = mtl, 
                     max.edge = 0.02,
                     offset = c(0.02,0.02),
                     cutoff = 0.01,
                     crs = st_crs(mtl))

# SPDE
SPDE <- inla.spde2.pcmatern(mesh=mesh,
                            alpha=2,
                            prior.range=c(0.05, 0.01),
                            prior.sigma=c(1, 0.01))

# Index matrix
Field <- inla.spde.make.index("field",n.spde=mesh$n)

# A matrix for estimation
AEst<-inla.spde.make.A(mesh,loc=as.matrix(lapinCoord))

# A matrix for prediction
APred<-inla.spde.make.A(mesh)

# For estimation
AEstlist <- list(AEst)

# For prediction
APredlist <- list(APred)

# Organise effect

# Estimation
effectEst <- list(i = 1:SPDE$n.spde)

# Prediction
effectPred <- list(i = 1:SPDE$n.spde)

# Stack for estimation
StackEst <- inla.stack(data=list(lapin = lapin$PA),
                       A = AEstlist,
                       effects = effectEst,
                       tag="est")

# Stack for prediction
StackPred <- inla.stack(data=list(lapin = NA),
                        A=APredlist,
                        effects=effectPred,
                        tag="pred")

# Organise StackEst and StackPred into a single stack
Stack <- inla.stack(StackEst,StackPred)

# Build model
model <- inla(lapin ~ 0 + f(i, model = SPDE),
              data = inla.stack.data(Stack),
              family="binomial",
              Ntrials=1,
              control.family =list(link="logit"),
              control.predictor=list(A=inla.stack.A(Stack),
                                     compute=TRUE, link = 1))

#===============
# Prediction map
#===============
# Dimension of the raster
rasterDim <- c(1000, 1500)

# Define basis of the map
mapBasis <- inla.mesh.projector(mesh,
                                dims = rasterDim,
                                xlim = c(st_bbox(mtl)[1], st_bbox(mtl)[3]),
                                ylim = c(st_bbox(mtl)[2], st_bbox(mtl)[4]),
                                crs = st_crs(mtl))

# Find the mesh edges on which predictions should be made
ID <- inla.stack.index(Stack, tag="pred")$data

# Calculate prediction
mapMean <- inla.mesh.project(mapBasis, 
                             model$summary.fitted.values[["mean"]][ID])

# Transform map into a raster
rastMean <- rast(nrows = rasterDim[1],
                 ncol = rasterDim[2],
                 crs = crs(mtl),
                 xmin = min(mapBasis$x), xmax = max(mapBasis$x),
                 ymin = min(mapBasis$y), ymax = max(mapBasis$y))

values(rastMean) <- as.vector(t(mapMean[,ncol(mapMean):1]))

# Mask of Montréal over the raster
lapinPredMask <- mask(rastMean,mtl)

saveRDS(lapinPredMask, file= "lapinMtl.RDS")

#==============================
# Calculate the range in meters
#==============================
x <- c(-73.8, -73.8 + model$summary.hyperpar$mean[1])
y <- c(45.4, 45.4)

twoPts <- st_as_sf(as.data.frame(cbind(x,y)),
                   coords = c("x", "y"),
                   crs = st_crs(mtl))

twoPtsProj <- st_transform(twoPts, crs = 32182)

dist(st_coordinates(twoPtsProj)) 
# Range = ~ 10200 m
model$summary.hyperpar$mean[2]
# Sill = ~ 3.12
```

If we estimate the parameters of the model presented in the previous slide we get a Gaussian process that looks like


```{r, echo = FALSE, fig.align="center"}
expVario <- function(d, nugget = 0, sill = 3.12, range = 10200){
  nugget + sill * (1 - exp(-d / range))
}

# The parameters were slightly 

par(mar = c(5.1, 5.5, 0.1, 0.1))
curve(expVario, 0, 45000, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 3.5),
      las = 1,
      xlab = "",
      ylab = "",
      cex.axis = 2,
      col = "blue")

mtext("Distance", side = 1, line = 3.5, cex = 2.5)
mtext("Variance", side = 2, line = 3.75, cex = 2.5)
```

. . .

What can we learn from this model ?

## Prediction map

```{r, echo =FALSE}
library(terra)
lapinMtl <- readRDS("./slides/data/lapinMtl.RDS")
mapview::mapview(lapinMtl) + 
mapview(list(present, absent),
      col.regions = list("lightblue", "hotpink"),
      color = list("blue", "hotpink"),
      legend = list(TRUE, TRUE))
```

## Kringing

If we want to interpolate across the region of interest, this is known as **kriging**.

. . .

**Simple kriging**

So far, we have seen the most simplistic Gaussian process where there is not even any intercept that is estimated. In short, the model is constructed using only the covariance function. 

. . .

In a linear regression perspective, this means that

$$\mathbf{y}\sim\mathcal{N}(0, f(d))$$

## Kringing {style="font-size: 0.9em;"}

::: {style="font-size: 1.1em;"}
**Ordinary kriging** 
:::

If we want to account for an intercept in the model such that 

$$\mathbf{y}\sim\mathcal{N}(\beta_0, f(d))$$

This is known as **ordinary kriging**.

. . .

::: {style="font-size: 1.1em;"}
**Universal kriging** 
:::

If we want to account for one or more explanatory variables in the model such that 

$$\mathbf{y}\sim\mathcal{N}(\beta_0 + \mathbf{X}\beta, f(d))$$
This is known as **Universal kriging**.
