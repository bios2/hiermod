---
title: "Gaussian process"
title-slide-attributes: 
  data-background-image: ../img/bg.jpg
  data-background-size: full
author: "Guillaume Blanchet -- Andrew MacDonald -- Vincent Tolon"
date: "2023-05-11"
execute:
  echo: true
format: 
  revealjs:
    theme: [default]
    logo: ../img/UdeS_logo_h_rgbHR.png
    transition: slide
    background-transition: fade
---

## Hierarchical models so far {style="font-size: 0.9em;"}

. . .

### An already (very !) general formulation

::: {style="font-size: 0.75em"}
So far, we have built hierarchical models that can be integrated into the following framework.
:::

. . .

::: {style="font-size: 0.8em"}
$$(\mathbf{y}|\mathbf{X},\mathbf{Z}, \boldsymbol{\beta}, \mathbf{b}, \sigma_\mathbf{y}^2)\sim \mathcal{MVN}(\mathbf{X} \boldsymbol{\beta} + \mathbf{Z}\mathbf{b}, \sigma_\mathbf{y}^2\mathbf{I})$$
:::

. . .

::: {style="font-size: 0.68em"}

where

$$\mathbf{b}\sim \mathcal{MVN}(\mu, \mathbf{\Sigma})$$
:::

. . .

::: {style="font-size: 0.65em"}

- $\mathbf{y}$ is a vector quantifying a response variable of length $n$
- $\mathbf{X}$ is a matrix of explanatory variables with $n$ rows (samples) and $p$ columns (explanatory variables) 
- $\boldsymbol{\beta}$ is a vector $p$ pararameters weighting the importance of each explanatory variables in $\mathbf{X}$
- $\sigma_\mathbf{y}^2$ is a measure of variance of the error in the regression model
- $\mathbf{I}$ is an $n \times n$ identity matrix 

:::: {style="color: blue"}
- $\mathbf{Z}$ is designed matrix of "explanatory" variables with $n$ rows (samples) and $q$ columns 
- $\mu$ is a vector defining the average importance of hierarchical parameters
- $\mathbf{\Sigma}$ is a matrix defining the covariance structure of hierarchical parameters
::::
:::

## Hierarchical models so far {style="font-size: 0.9em;"}

### An already (very !) general formulation

Another way to write this generalized formulation is

$$\mathbf{y}_i = \mathbf{X}_{ij} \boldsymbol{\beta}_j + \mathbf{Z}_{ik}\mathbf{b}_{k} + \boldsymbol{\varepsilon}_{ij}$$
where

$$\mathbf{b}\sim \mathcal{MVN}(\mu, \mathbf{\Sigma})$$
and 

$$\varepsilon \sim \mathcal{N}(0, \sigma^2)$$

## Even more complex hierarchical models!? {style="font-size: 0.9em;"}

So far we have seen many (!) versions of hierarchical models, which got increasingly more complex in their structure.

. . .

Let's continue on that slippery slope... 

. . . 

Would you know how to constraint (spatially, temporally, phylogenetically, etc.) such a model ?

![](https://www.i2symbol.com/pictures/emojis/f/c/3/2/fc326fef420c2381348864310ea8efa1_384.png){fig-align="center" width=30%}

## Even more complex hierarchical models! {style="font-size: 0.8em;"}

If we get back to a model that has a single hierarchy on the intercept such that

$$\mathbf{y} \sim \mathcal{N}(\mathbf{b},\sigma^2)$$

. . .

where

$$\mathbf{b} \sim \mathcal{N}(\mu, \sigma^2)$$

. . . 

If we want to account for a constraint on the previously presented model we can rewrite the equation fo $\mathbf{b}$ as 

$$\mathbf{b} \sim \mathcal{N}\left(\mu, f(d)\right)$$

. . .

where

- $f(d)$ is a function of a distance matrix

## Even more complex hierarchical models! {style="font-size: 0.9em;"}

$$\mathbf{b} \sim \mathcal{N}\left(\mu, f(d)\right)$$

. . .

What this equation means conceptually is that the variance associated to $\mathbf{b}$ is not a constant, it changes based on distance (across space, time, phylogeny, etc.). This is known as a **Gaussian process**.

![](https://t4.ftcdn.net/jpg/05/69/50/21/240_F_569502134_d2TO2BeHCbvOn4imEyFJJ5n6HdiyJg9X.jpg){fig-align="center" width=30%}

## A bit of history

. . .

In statistics, Gaussian processes have a unique history. The development of this type of model is closely linked to the estimation of mineral deposits. 

. . .

Spatial Gaussian processes are also called **geostatistical** models, where the prefix *geo* refers to geology, not geography, as one may be led to believe.

. . .

As mining engineers are at the root of the development of Gaussian processes, the language associated with this type of model is influenced by this field. 

## A bit of history

Gaussian processes have been developed in the 1950s by 

::::{.columns}
::: {.column width="50%"}
![](https://www.nae.edu/File.aspx?id=191706){fig-align="center" width=60%}

:::::{style="font-size: 0.9em;"}
Daniel G. Krige (1919–2013)
:::::
:::
::: {.column width="50%"}
![](https://upload.wikimedia.org/wikipedia/commons/5/5c/Georges_Matheron.jpg){fig-align="center" width=75%}

:::::{style="font-size: 0.9em;"}
Georges Mathéron (1930–2000)
:::::

:::
::::

## Assumption with Gaussian processes

. . .

In general, when defining a Gaussian process, we make the following assumptions:

. . .

- The closer two sites are, the more similar they are.

. . .

- After a certain distance, it is no longer necessary to consider that a site influences another site.

. . .


**Note** The distance of influence of a site on another can be different depending on what is being studied, where it is being studied and when it is being studied

## $f(d)$

. . .

So, what does $f(d)$ looks like exactly ?

. . .

In theory, $f(d)$ can be anything... 

. . .

However, in practice, there are particularities of the functions that are defined by the assumptions we impose on our model.

. . . 

As such, here is a classic structure these variance function take

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")
```

## $f(d)$ - A bit of vocabulary

. . .

### Nugget effect

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 1,
       y0 = 0,
       x1 = 1,
       y1 = 2,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```

## $f(d)$ - A bit of vocabulary

### Range


```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 0,
       y0 = 1,
       x1 = 30,
       y1 = 1,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```


## $f(d)$ - A bit of vocabulary

### Sill

```{r, echo=FALSE, fig.align='center', fig.height= 3.5}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")

arrows(x0 = 60,
       y0 = 2,
       x1 = 60,
       y1 = 7,
       length = 0.2,
       angle = 15,
       ljoin = "bevel",
       code = 3,
       lwd = 7,
       col = "orange")
```

## $f(d)$ - types of functions {style="font-size: 0.85em;"}

. . .

Many functions have been proposed have this general shape

. . . 

In this lecture, we will use the exponential function

$$C_0 + C_1 \left(1-e^{-d/a}\right)$$

. . .

where

- $C_0$ is the nugget effect

. . .

- $C_1$ is the sill

. . .

- $d$ is the distance

. . .

- $a$ is the range

## Exponential function

Nugget : 2 -- Sill : 5 -- Range : 10

```{r, echo = FALSE}
expVario <- function(d, nugget = 2, sill = 5, range = 10){
  nugget + sill * (1 - exp(-d / range))
}

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 100, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 7),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")
```

## An illustrative example {style="font-size: 0.9em;"}

. . . 

To present how Gaussian processes can be used, let's study the distribution of *Sylvilagus oviparus* in Montréal.

. . .

### A few characteristics of *Sylvilagus oviparus* 

- They are found mainly in urban parks of Montréal and are very efficient at hiding in hollow trees and burrows.

. . .

- They lay their eggs (often pastel-coloured) on the Sunday following the first full moon after the spring equinox. 

. . .

- They move well in an urban  setting and are not affected by the level of urbanisation


## A typical member of the species

![](https://t3.ftcdn.net/jpg/05/78/06/66/240_F_578066681_18vcVGHuSLDc4dQE6HTXG8qsn2tjSHMy.jpg){fig-align="center" width=75%}

## Distribution of *S. oviparus* in Montréal {style="font-size: 0.9em;"}

. . .

In 2015, a survey was carried out to find *Sylvilagus oviparus* in Montréal's park. Here are the data
. . .

::::{.columns}
:::{.column width="60%"}
```{r, echo = FALSE}
library(mapview)
explan<-readRDS("./slides/data/explanaNest.RDS")
lapin <- readRDS("./slides/data/lapin.RDS")

# Carte de présence absence en 2015
present <- explan[lapin$PA == 1,]
absent <- explan[lapin$PA == 0,]

# Map species
mapview(list(present, absent),
        col.regions = list("lightblue", "hotpink"),
        color = list("blue", "hotpink"),
        legend = list(TRUE, TRUE))
```
:::
:::{.column width="40%"}

:::::{style="font-size: 0.8em;"}
Within the censused park

- <span style="color:blue;">Blue parks</span> : observed

- <span style="color:#FF33FF;">Pink parks</span> : not observed
:::::
:::
::::

## Model

. . .

Since we have presence-absence data

$$P(y = 1) = \frac{\exp(b)}{1 - \exp(b)}$$

. . .

where 
$$b \sim{\cal N}\left(0, C_0 +C_1\left(1 - e^{\frac{-d}{a}}\right)\right)$$

## Fitting the model

If we estimate the parameters of the model presented in the previous slide we get a Gaussian process that looks like


```{r, echo = FALSE, fig.align="center"}
expVario <- function(d, nugget = 0.2, sill = 4, range = 150){
  nugget + sill * (1 - exp(-d / range))
}

# The parameters were slightly 

par(mar = c(5.1, 5.1, 0.1, 0.1))
curve(expVario, 0, 700, 
      lwd = 5,
      bty = "L",
      ylim = c(0, 4.1),
      las = 1,
      xlab = "Distance",
      ylab = "Variance",
      cex.lab = 2.5,
      cex.axis = 2,
      col = "blue")


```

. . .

What can we learn from this model ?

## Kringing

If we want to interpolate across the region of interest, this is known as **kriging**.

. . .

### Simple kriging

So far, we have seen the most simplistic Gaussian process where there is not even any intercept that is estimated. In short, the model is constructed using only the covariance function. 

. . .

In a linear regression perspective, this means that

$$\mathbf{y}\sim\mathcal{N}(0, f(d))$$

## Kringing {style="font-size: 0.9em;"}

::: {style="font-size: 1.1em;"}
**Ordinary kriging** 
:::

If we want to account for an intercept in the model such that 

$$\mathbf{y}\sim\mathcal{N}(\beta_0, f(d))$$

This is known as **ordinary kriging**.

. . .

::: {style="font-size: 1.1em;"}
**Universal kriging** 
:::

If we want to account for one or more explanatory variables in the model such that 

$$\mathbf{y}\sim\mathcal{N}(\beta_0 + \mathbf{X}\beta, f(d))$$
This is known as **Universal kriging**.

## Prediction map

```{r, echo =FALSE}
lapinMtlraster <- readRDS("./slides/data/lapinMtl.RDS")
mapview::mapview(lapinMtlraster)
```
